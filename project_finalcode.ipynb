{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiA60U0xafh+V++KduKqB7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2ovisa/AH2179/blob/main/project_finalcode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stop ahead prediction\n",
        "*the code was computed with the help from previous exercises, AI and https://towardsdatascience.com/6-methods-for-multi-step-forecasting-823cbde4127a/*\n",
        "\n"
      ],
      "metadata": {
        "id": "8zgv_111ILlV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preparation"
      ],
      "metadata": {
        "id": "xWW656Aietcn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6U2Qaqd29AC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform, randint\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "\n",
        "#-------------------------------------------------data preprocessing------------------------------------------------------------------\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/zhenliangma/Applied-AI-in-Transportation/master/ProjectAssignmentData/Dataset-PT.csv'\n",
        "df = pd.read_csv(url, header = 1)\n",
        "#print(df.head(30))\n",
        "#df.info()\n",
        "#print(df.columns.tolist())\n",
        "#df = df.iloc[:1000]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create unique trips\n",
        "df = df.sort_values(['bus_id', 'Calendar_date', 'stop_sequence']).reset_index(drop=True)\n",
        "\n",
        "df['trip_number'] = df.groupby(['bus_id','Calendar_date', 'stop_sequence']).cumcount()\n",
        "df['unique_trip'] = (\n",
        "    df['bus_id'].astype(str) + '_' +\n",
        "    df['Calendar_date'].astype(str) + '_' +\n",
        "    df['trip_number'].astype(str)\n",
        ")"
      ],
      "metadata": {
        "id": "Sd5WV0j-8wls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reasure that all trips contains 27 stops\n",
        "stops_ok = (\n",
        "    df.groupby('unique_trip')['stop_sequence']\n",
        "      .apply(lambda s: set(s.tolist()) == set(range(1,28)))\n",
        "      .all()\n",
        ")\n",
        "print('Stops exakt 1..27 per trip:', stops_ok)\n",
        "\n",
        "#Reasure that stop sequence is striclty increased by one step\n",
        "mono_ok = (\n",
        "    df.groupby('unique_trip')['stop_sequence']\n",
        "      .apply(lambda s: (s.diff().fillna(1) == 1).all())\n",
        "      .all()\n",
        ")\n",
        "print('Strikt +1 mellan rader inom trip:', mono_ok)\n",
        "\n",
        "#Each of the horizons are looking at the right trip\n",
        "for h in [1,3,6,12]:\n",
        "    s_future = df.groupby('unique_trip')['stop_sequence'].shift(-h)\n",
        "    ok = (s_future.dropna() - df.loc[s_future.notna(), 'stop_sequence'] == h).all()\n",
        "    print(f'H={h} korrekt skift:', ok)\n",
        "\n",
        "#the shift do not cross\n",
        "for h in [1,3,6,12]:\n",
        "    uid_future = df.groupby('unique_trip')['unique_trip'].shift(-h)\n",
        "    cross_ok = (uid_future.dropna() == df.loc[uid_future.notna(), 'unique_trip']).all()\n",
        "    print(f'H={h} ingen kors-trip:', cross_ok)\n"
      ],
      "metadata": {
        "id": "8f3PRuKY4bpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Create the target values*"
      ],
      "metadata": {
        "id": "PBKS2UeEhAp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#multi horizon targets\n",
        "\n",
        "for h in [1,3,6,12]:\n",
        "  df[f'arrival_delay_t+{h}'] = df.groupby('unique_trip')['arrival_delay'].shift(-h)\n",
        "\n",
        "# ta bort rader som saknar alla  target\n",
        "targets = [f\"arrival_delay_t+{h}\" for h in [1, 3, 6, 12]]\n",
        "df = df[df[targets].notna().any(axis=1)].copy()"
      ],
      "metadata": {
        "id": "_6kGeFf5j7AS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Feature Engineering*"
      ],
      "metadata": {
        "id": "o85hAmI3hHXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalizes the stop index\n",
        "df[\"stop_sequence_norm\"] = df.groupby(\"unique_trip\")[\"stop_sequence\"].transform(\n",
        "    lambda x: (x - x.min()) / (x.max() - x.min())\n",
        ")\n",
        "\n",
        "#The amount of stops remaining in the route\n",
        "df[\"stops_remaining\"] = df.groupby(\"unique_trip\")[\"stop_sequence\"].transform(\n",
        "    lambda x: x.max() - x\n",
        ")\n",
        "\n",
        "#Change in delay compared to previous stop\n",
        "df[\"delay_diff\"] = df.groupby(\"unique_trip\")[\"arrival_delay\"].diff().fillna(0)\n",
        "\n",
        "#Moving Average of last 3 stops\n",
        "df[\"delay_ma3\"] = df.groupby(\"unique_trip\")[\"arrival_delay\"].transform(\n",
        "    lambda x: x.rolling(window=3, min_periods=1).mean()\n",
        ")\n",
        "#Difference between current delay and moving average\n",
        "df[\"delay_trend\"] = df[\"arrival_delay\"] - df[\"delay_ma3\"]\n"
      ],
      "metadata": {
        "id": "roGTfwCO6SwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###EDA"
      ],
      "metadata": {
        "id": "4kSW_o7HvnbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Descriptive statisrtcs\n",
        "print(df[\"arrival_delay\"].mean())\n",
        "print(df[\"arrival_delay\"].median())\n",
        "#df[\"arrival_delay\"].hist(bins=50)"
      ],
      "metadata": {
        "id": "Y3AsuMFvvpBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Plot of the distribution of arrival delay for each stop*"
      ],
      "metadata": {
        "id": "MYzz_W-hhrhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "sns.scatterplot(data=df, x=\"stop_sequence\", y=\"arrival_delay\", alpha=0.3)\n",
        "\n",
        "#mean trend line\n",
        "sns.lineplot(data=df, x=\"stop_sequence\", y=\"arrival_delay\",\n",
        "             estimator=\"mean\", ci=None, color=\"red\", linewidth=2, label=\"Average delay\")\n",
        "\n",
        "#reference line at 0 delay\n",
        "plt.axhline(0, color=\"black\", linestyle=\"--\", alpha=0.7)\n",
        "\n",
        "plt.xlabel(\"Stop sequence\")\n",
        "plt.ylabel(\"Arrival delay (s)\")\n",
        "plt.title(\"Arrival delay against stop sequence\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "w5pEdOkTvyZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Correlations*"
      ],
      "metadata": {
        "id": "1-LSsgC-h73Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#heatmap, arrival delays and dummies\n",
        "corr = df[[\"arrival_delay\",\"factor(weather)Snow\", \"factor(weather)Rain\", \"factor(weather)Normal\", \"factor(time_of_day)Morning_peak\", \"factor(time_of_day)Afternoon_peak\", \"factor(day_of_week)weekend\", \"factor(day_of_week)weekday\",\"factor(temperature)Cold\",\"factor(temperature)Extra_cold\" ]].corr()\n",
        "\n",
        "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", center=0)\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LxLBpjcGh6jY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation of each feature with arrival_delay\n",
        "\n",
        "df_numeric = df.select_dtypes(include=['number'])\n",
        "\n",
        "corr_matrix = df_numeric.corr()\n",
        "\n",
        "arrival_corr = corr_matrix['arrival_delay'].sort_values(ascending=False)\n",
        "print(arrival_corr)"
      ],
      "metadata": {
        "id": "cbmLtvIJiE_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data preprocessing"
      ],
      "metadata": {
        "id": "f5wrsh2ZxFXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_trips = df[\"unique_trip\"].unique()\n",
        "split_point = int(len(unique_trips) * 0.8)\n",
        "train_trips = unique_trips[:split_point]\n",
        "test_trips = unique_trips[split_point:]\n",
        "\n",
        "#create a mask\n",
        "train_mask = df[\"unique_trip\"].isin(train_trips)\n",
        "test_mask = ~train_mask\n",
        "\n"
      ],
      "metadata": {
        "id": "3-Zgcd7r7dfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a copy for visualization later\n",
        "df_vis = df.copy()\n",
        "\n",
        "drop_cols = [\n",
        "    \"Calendar_date\", \"bus_id\", \"route_id\", \"arrival_time\",\n",
        "    \"unique_trip\", \"new_trip\", \"trip_number\"\n",
        "]\n",
        "df = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
        "\n",
        "#baseline dummies are removed to avoid multicollinearity\n",
        "to_drop = [\"factor(weather)Normal\", \"factor(temperature)Normal\",\n",
        "           \"factor(day_of_week)weekend\", \"factor(time_of_day)Off-peak\"]\n",
        "df = pd.get_dummies(df, drop_first=False)\n",
        "\n",
        "df = df.drop(columns=[c for c in to_drop if c in df.columns], errors=\"ignore\")\n",
        "\n",
        "#advanced its features are removed for the existing ITS\n",
        "df_existing_its = df.copy()\n",
        "drop_its = ['upstream_stop_delay',\n",
        "'previous_bus_delay',\n",
        "'previous_trip_travel_time',\n",
        "'travel_time_for_previous_section',\n",
        "'dwell_time',\n",
        "'traffic_condition',\n",
        "'recurrent_delay',\n",
        "'delay_diff',\n",
        "'delay_ma3',\n",
        "'delay_trend']\n",
        "\n",
        "df_existing_its = df_existing_its.drop(columns=[c for c in drop_its if c in df.columns])"
      ],
      "metadata": {
        "id": "EgnMW4KexKYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Existing ITS*"
      ],
      "metadata": {
        "id": "3JoS6aZuil79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#existing its\n",
        "#targets\n",
        "X_eits = df_existing_its.drop([\"arrival_delay\"] + targets, axis=1, errors=\"ignore\")\n",
        "y_eits = df_existing_its[targets]\n",
        "\n",
        "#fill missing values\n",
        "y_eits = y_eits.fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "X_train_eits, X_test_eits = X_eits[train_mask], X_eits[test_mask]\n",
        "y_train_eits, y_test_eits = y_eits[train_mask], y_eits[test_mask]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_eits = scaler.fit_transform(X_train_eits)\n",
        "X_test_eits = scaler.transform(X_test_eits)"
      ],
      "metadata": {
        "id": "g4lkzhgbii7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Advanced ITS*"
      ],
      "metadata": {
        "id": "Lcqxzrw8ikHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#targets\n",
        "X = df.drop([\"arrival_delay\"] + targets, axis=1, errors=\"ignore\")\n",
        "y = df[targets]\n",
        "\n",
        "#missing values are filled\n",
        "y = y.fillna(method='ffill').fillna(method='bfill')"
      ],
      "metadata": {
        "id": "gR0BbRbwsuTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = X[train_mask], X[test_mask]\n",
        "y_train, y_test = y[train_mask], y[test_mask]"
      ],
      "metadata": {
        "id": "O0kqn8p6JK7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scale\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "YAiXeXi8z5Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Randomized Search*"
      ],
      "metadata": {
        "id": "nlmlO3JNi-Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For XGBregressor\n",
        "param_dist = {\n",
        "    'n_estimators': [200, 400, 600, 800],\n",
        "    'max_depth': [2, 4, 6, 8, 10],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'subsample': [0.5, 0.7, 0.9],\n",
        "    'colsample_bytree': [0.5, 0.7, 0.9]\n",
        "}\n",
        "\n",
        "rand_search = RandomizedSearchCV(\n",
        "    XGBRegressor(tree_method='hist', random_state=42),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=30,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rand_search.fit(X_train, y_train)\n",
        "print(\"Best params:\", rand_search.best_params_)\n"
      ],
      "metadata": {
        "id": "wkxIiw0WtUOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for Random Forest Regressor\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 80, 100, 200],\n",
        "    'max_depth': [4, 8, 10, 15],\n",
        "    'min_samples_split': [10, 12, 15],\n",
        "    'min_samples_leaf': [2, 4, 6 ],\n",
        "}\n",
        "\n",
        "rand_search = RandomizedSearchCV(\n",
        "    RandomForestRegressor(random_state=0),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=3,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rand_search.fit(X_train, y_train)\n",
        "print(\"Best params:\", rand_search.best_params_)"
      ],
      "metadata": {
        "id": "XREMVy9LTzPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for K Neighbors\n",
        "param_dist = {\n",
        "    'n_neighbors': [3, 5, 7, 10],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'p': [1, 2]\n",
        "}\n",
        "\n",
        "rand_search = RandomizedSearchCV(\n",
        "    KNeighborsRegressor(),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=3,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rand_search.fit(X_train, y_train)\n",
        "print(\"Best params:\", rand_search.best_params_)\n",
        "\n",
        "#Best params: {'weights': 'distance', 'p': 1, 'n_neighbors': 10"
      ],
      "metadata": {
        "id": "kkMG9vr7DmVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multi-output models"
      ],
      "metadata": {
        "id": "qKzfa4OQxx1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*KNN*"
      ],
      "metadata": {
        "id": "3PyNkxF95jZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "\n",
        "model = KNeighborsRegressor(n_neighbors=10, weights=\"distance\", p=1)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#Predict on the test set\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "CY37veBrMEkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*Random Forest Regressor*"
      ],
      "metadata": {
        "id": "aWxGf-7y5nHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=80, max_depth=15, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#Prediktion\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "ChvitN5-68EG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#multioutput with wrapped\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "\n",
        "model = MultiOutputRegressor(\n",
        "    RandomForestRegressor(n_estimators=80, max_depth=15, random_state=42)\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "0LO3Z6cBkCxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*XGBoost*"
      ],
      "metadata": {
        "id": "9ZDTYr2W5r4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "model = XGBRegressor(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=4,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.5,\n",
        "        random_state=42,\n",
        "        tree_method='hist'\n",
        "    )\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "2YWkRQYBXWxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#multioutput with wrapped\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "\n",
        "xgb_model = MultiOutputRegressor(\n",
        "    XGBRegressor(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=4,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.5,\n",
        "        random_state=42,\n",
        "        tree_method='hist'\n",
        "    )\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "Mhvpo2OGtM2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##*Chained multi-output*"
      ],
      "metadata": {
        "id": "3PyJjpfFxCD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost\n",
        "from sklearn.multioutput import RegressorChain\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "base_model = XGBRegressor(n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=4,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.5,\n",
        "        random_state=42,\n",
        "        tree_method='hist'\n",
        "    )\n",
        "\n",
        "chain = RegressorChain(base_model, order =[0,1,2,3]) #0=t+1,1=t+3 osv\n",
        "chain.fit(X_train, y_train)\n",
        "\n",
        "y_pred = chain.predict(X_test)"
      ],
      "metadata": {
        "id": "lFKDJE6QxHM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random forest\n",
        "from sklearn.multioutput import RegressorChain\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "base_model = RandomForestRegressor(n_estimators=80, max_depth=15, random_state=42)\n",
        "\n",
        "chain = RegressorChain(base_model, order =[0,1,2,3]) #0=t+1,1=t+3 osv\n",
        "chain.fit(X_train, y_train)\n",
        "\n",
        "y_pred = chain.predict(X_test)\n"
      ],
      "metadata": {
        "id": "aDSnIk1Ni_CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*Existing ITS*"
      ],
      "metadata": {
        "id": "hJwlrYXSkbGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multioutput import RegressorChain\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "#base_model_eits = XGBRegressor(n_estimators=400, learning_rate=0.05, max_depth=8,\n",
        "#                          subsample=0.8, colsample_bytree=0.8, random_state=42,\n",
        "#                          tree_method='hist')\n",
        "\n",
        "base_model_eits = RandomForestRegressor(n_estimators=80, max_depth=15, random_state=42)\n",
        "\n",
        "chain = RegressorChain(base_model_eits, order =[0,1,2,3]) #0=t+1,1=t+3 osv\n",
        "chain.fit(X_train_eits, y_train_eits)\n",
        "\n",
        "y_pred_eits = chain.predict(X_test_eits)"
      ],
      "metadata": {
        "id": "Wes4DGaDJmJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*LSTM*\n",
        "- *this is computed with the help of AI*"
      ],
      "metadata": {
        "id": "82-H-yU73Qfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "timesteps = 5\n",
        "horizons = [1, 3, 6, 12]\n",
        "features = [\"arrival_delay\"]\n",
        "\n",
        "X_list, y_list = [], []\n",
        "\n",
        "for trip_id, trip_data in df_vis.groupby(\"unique_trip\"):\n",
        "    arr = trip_data[features].values\n",
        "    delays = trip_data[\"arrival_delay\"].values\n",
        "\n",
        "    for i in range(len(trip_data) - timesteps - max(horizons)):\n",
        "        # input sequence\n",
        "        X_list.append(arr[i:i+timesteps])\n",
        "\n",
        "        # targets\n",
        "        y_list.append([delays[i+timesteps+h-1] for h in horizons])\n",
        "\n",
        "X = np.array(X_list)   # shape: (samples, timesteps, features)\n",
        "y = np.array(y_list)   # shape: (samples, len(horizons))\n"
      ],
      "metadata": {
        "id": "jdsCY8Ep3R1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAIN AND TEST SPLIT\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "1tHVzMQJ3ZLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(timesteps, X.shape[2])))\n",
        "model.add(Dense(len(horizons)))   # en output per horisont\n",
        "model.compile(optimizer=\"adam\", loss=\"mae\")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "W-vpvjBy3bHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2\n",
        ")\n"
      ],
      "metadata": {
        "id": "2WMjQgBx3gNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "for i, h in enumerate(horizons):\n",
        "    mae = mean_absolute_error(y_test[:, i], y_pred[:, i])\n",
        "    r2  = r2_score(y_test[:, i], y_pred[:, i])\n",
        "    print(f\"Horizon t+{h}: MAE={mae:.2f}, R²={r2:.3f}\")\n"
      ],
      "metadata": {
        "id": "UoKSwz6v3jNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evalutation"
      ],
      "metadata": {
        "id": "FPszd2q_55Fq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Average delay per stop*"
      ],
      "metadata": {
        "id": "JhAL9ysglJVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Shift the predictions back to get to their stop. This is done only for better visulisation\n",
        "pred_df = pd.DataFrame(y_pred, columns=[f\"pred_t+{h}\" for h in [1,3,6,12]])\n",
        "pred_df[\"stop_sequence\"] = df_vis.loc[test_mask, \"stop_sequence\"].values\n",
        "pred_df[\"unique_trip\"] = df_vis.loc[test_mask, \"unique_trip\"].values\n",
        "pred_df[\"arrival_delay\"] = df_vis.loc[test_mask, \"arrival_delay\"].values\n",
        "\n",
        "for h in [1,3,6,12]:\n",
        "    pred_df[f\"pred_t+{h}_aligned\"] = (\n",
        "        pred_df.groupby(\"unique_trip\")[f\"pred_t+{h}\"].shift(h)\n",
        "    )"
      ],
      "metadata": {
        "id": "jRN9PjZ8kh9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average delay per stop\n",
        "avg_aligned = pred_df.groupby(\"stop_sequence\")[[\"arrival_delay\"] +\n",
        "    [f\"pred_t+{h}_aligned\" for h in [1,3,6,12]]].mean()\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(avg_aligned.index, avg_aligned[\"arrival_delay\"], label=\"Actual\", marker='o')\n",
        "for h in [1,3,6,12]:\n",
        "    plt.plot(avg_aligned.index, avg_aligned[f\"pred_t+{h}_aligned\"], '--', label=f\"Predicted t+{h}\")\n",
        "plt.xlabel(\"Stop sequence\")\n",
        "plt.ylabel(\"Average Delay (s)\")\n",
        "plt.title(\"Average Delay Prediction Aligned per Stop (MultiOutputRegressor RF)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "icRy5PkLlEay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Feature importance*"
      ],
      "metadata": {
        "id": "4IuwG0TelL4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature importance for RegressonChain\n",
        "#collect feature importances per horizon\n",
        "feature_names = list(X.columns)\n",
        "importances = []\n",
        "for i, est in enumerate(chain.estimators_):\n",
        "    # base + previous predictions for later horizons\n",
        "    extra = [f\"y_pred_t+{[1,3,6,12][j]}\" for j in range(i)]\n",
        "    feats = feature_names + extra\n",
        "    imp = pd.Series(est.feature_importances_, index=feats).sort_values(ascending=False)\n",
        "    importances.append(imp)\n",
        "\n",
        "#plot top features per horizon\n",
        "plt.figure(figsize=(14, 10))\n",
        "for i, (imp, h) in enumerate(zip(importances, [1,3,6,12])):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    top_imp = imp.head(10)\n",
        "    top_imp[::-1].plot(kind=\"barh\")  # reverse for readable order\n",
        "    plt.title(f\"Horizon t+{h}\")\n",
        "    plt.xlabel(\"Importance\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zgEegE0Slofl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance for MultiOutputRegressor\n",
        "feature_names = list(X.columns)\n",
        "importances = []\n",
        "\n",
        "for i, est in enumerate(model.estimators_):  # one estimator per horizon\n",
        "    imp = pd.Series(est.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
        "    importances.append(imp)\n",
        "\n",
        "# plot top features per horizon\n",
        "plt.figure(figsize=(14, 10))\n",
        "for i, (imp, h) in enumerate(zip(importances, [1,3,6,12])):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    top_imp = imp.head(10)\n",
        "    top_imp[::-1].plot(kind=\"barh\")  # reverse for readability\n",
        "    plt.title(f\"Horizon t+{h}\")\n",
        "    plt.xlabel(\"Importance\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Z9sODgnZmlyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances = model.feature_importances_\n",
        "\n",
        "feat_imp = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "#top 5 features\n",
        "print(feat_imp.head(5))\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8,6))\n",
        "feat_imp.head(10).plot(kind=\"barh\")\n",
        "plt.title(\"Top 10 Feature Importances (Shared across all horizons)\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ANX969JfQsVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Metrics*"
      ],
      "metadata": {
        "id": "B9cprHGElhkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae = mean_absolute_error(y_test, y_pred, multioutput='raw_values')\n",
        "r2 = [r2_score(y_test.iloc[:, i], y_pred[:, i]) for i in range(y_test.shape[1])]\n",
        "\n",
        "for i, col in enumerate(y_test.columns):\n",
        "    print(f\"{col}: MAE={mae[i]:.2f}, R²={r2[i]:.3f}\")\n"
      ],
      "metadata": {
        "id": "J3sL4Mf2tUe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#existing its\n",
        "mae = mean_absolute_error(y_test_eits, y_pred_eits, multioutput='raw_values')\n",
        "r2 = [r2_score(y_test_eits.iloc[:, i], y_pred_eits[:, i]) for i in range(y_test.shape[1])]\n",
        "\n",
        "for i, col in enumerate(y_test_eits.columns):\n",
        "    print(f\"{col}: MAE={mae[i]:.2f}, R²={r2[i]:.3f}\")"
      ],
      "metadata": {
        "id": "WKi1fCDSKQo_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}